# Deploy Autom√°tico para GCP VM
#
# Este workflow faz deploy para Google Cloud Platform usando:
#   - VM: e2-small no GCP Compute Engine
#   - DB: Cloud SQL PostgreSQL
#   - Containers: Docker Compose
#
# Secrets necess√°rios (sincronize com scripts/sync-secrets.ps1):
#   - GCP_SA_KEY: Service Account JSON do GCP
#   - Todas as vari√°veis de ambiente do .env.production (80+ vari√°veis)
#
# Como usar:
#   1. Editar .env.production com valores de produ√ß√£o
#   2. Sincronizar secrets: .\scripts\sync-secrets.ps1 -Repository "usuario/repo"
#   3. Push para master: git push origin master
#
# Durante o deploy, o workflow ir√° criar dinamicamente:
#   - backend/.env (vari√°veis do Laravel)
#   - frontend/.env (vari√°veis do Angular)
#   - .env.production (vari√°veis do Docker Compose)

name: Deploy to Production

on:
  push:
    branches:
      - master
      - main
  workflow_dispatch:

env:
  PROJECT_ID: tccutfpets
  VM_NAME: tccutfpets
  VM_ZONE: southamerica-east1-b
  APP_DIR: /opt/utfpets
  BACKUP_DIR: /opt/utfpets_backups

jobs:
  deploy:
    name: Deploy to VM
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Prepare deployment
        run: |
          echo "üöÄ Starting deployment to VM ${VM_NAME}..."
          echo "üì¶ Commit: ${{ github.sha }}"
          echo "üë§ Author: ${{ github.actor }}"

      - name: Install Docker and prepare VM
        run: |
          echo "üîß Installing Docker and preparing VM..."

          gcloud compute ssh ${VM_NAME} \
            --zone=${VM_ZONE} \
            --project=${PROJECT_ID} \
            --ssh-flag="-o ServerAliveInterval=60" \
            --ssh-flag="-o ConnectTimeout=120" \
            --command="
              set -e

              echo 'üì¶ Checking Docker installation...'
              if ! command -v docker &> /dev/null; then
                echo 'Installing Docker Engine...'
                sudo apt-get update -qq
                sudo apt-get install -y ca-certificates curl
                sudo install -m 0755 -d /etc/apt/keyrings
                sudo curl -fsSL https://download.docker.com/linux/debian/gpg -o /etc/apt/keyrings/docker.asc
                sudo chmod a+r /etc/apt/keyrings/docker.asc
                echo \"deb [arch=\$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/debian \$(. /etc/os-release && echo \\\"\$VERSION_CODENAME\\\") stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
                sudo apt-get update -qq
                sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
                sudo usermod -aG docker \$USER
                echo '‚úÖ Docker installed'
              else
                echo '‚úÖ Docker already installed'
              fi

              echo 'üìÅ Creating application directory...'
              sudo mkdir -p ${APP_DIR}
              sudo chown \$USER:\$USER ${APP_DIR}

              echo 'üìÅ Creating backup directory...'
              sudo mkdir -p ${BACKUP_DIR}

              if [ -d ${APP_DIR} ] && [ \"\$(ls -A ${APP_DIR})\" ] && command -v docker &> /dev/null; then
                echo '‚è∏Ô∏è  Stopping containers...'
                cd ${APP_DIR}
                docker compose down || true

                echo 'üíæ Creating backup...'
                BACKUP_NAME=utfpets_\$(date +%Y%m%d_%H%M%S)
                sudo cp -r ${APP_DIR} ${BACKUP_DIR}/\${BACKUP_NAME}
                echo \"‚úÖ Backup created: \${BACKUP_NAME}\"
              else
                echo '‚ÑπÔ∏è  First deployment - no backup needed'
              fi
            "

      - name: Copy files to VM
        run: |
          echo "üìÅ Copying application files..."

          # Criar lista de exclus√µes (n√£o sobrescrever .env, vendor, etc)
          cat > /tmp/rsync-exclude.txt <<EOF
          .git
          .github
          node_modules
          vendor
          .env
          .env.example
          storage/logs/*
          storage/framework/cache/*
          storage/framework/sessions/*
          storage/framework/views/*
          storage/keys/gcp-service-account.json
          bootstrap/cache/*.php
          tests
          phpunit.xml
          .gitignore
          .editorconfig
          EOF

          # Copiar arquivos excluindo os listados
          gcloud compute scp \
            --recurse \
            --zone=${VM_ZONE} \
            --project=${PROJECT_ID} \
            --compress \
            ./* ${VM_NAME}:${APP_DIR}/ \
            2>&1 | grep -v "Warning: Permanently added" | grep -v ".env" | grep -v "vendor" || true

      - name: Create backend .env file
        run: |
          echo "üìù Creating backend/.env file from GitHub Secrets..."

          cat > /tmp/backend.env <<'EOF'
          # Application
          APP_NAME="${{ secrets.APP_NAME || 'UTFPets API' }}"
          APP_ENV=production
          APP_KEY=${{ secrets.APP_KEY }}
          APP_DEBUG=false
          APP_TIMEZONE="${{ secrets.APP_TIMEZONE || 'America/Sao_Paulo' }}"
          APP_URL=${{ secrets.APP_URL }}
          APP_LOCALE="${{ secrets.APP_LOCALE || 'pt_BR' }}"
          APP_FALLBACK_LOCALE="${{ secrets.APP_FALLBACK_LOCALE || 'pt_BR' }}"
          APP_FAKER_LOCALE="${{ secrets.APP_FAKER_LOCALE || 'pt_BR' }}"
          APP_MAINTENANCE_DRIVER="${{ secrets.APP_MAINTENANCE_DRIVER || 'file' }}"
          APP_MAINTENANCE_STORE="${{ secrets.APP_MAINTENANCE_STORE || 'database' }}"

          BCRYPT_ROUNDS=${{ secrets.BCRYPT_ROUNDS || 12 }}

          # URLs
          API_PUBLIC_URL="${{ secrets.API_PUBLIC_URL || secrets.APP_URL }}"
          FRONTEND_URL="${{ secrets.FRONTEND_URL || 'https://utfpets.online' }}"

          # Logging
          LOG_CHANNEL="${{ secrets.LOG_CHANNEL || 'stack' }}"
          LOG_STACK="${{ secrets.LOG_STACK || 'daily' }}"
          LOG_DEPRECATIONS_CHANNEL="${{ secrets.LOG_DEPRECATIONS_CHANNEL || 'null' }}"
          LOG_LEVEL="${{ secrets.LOG_LEVEL || 'error' }}"

          # Google Cloud
          GOOGLE_CLOUD_PROJECT="${{ secrets.GOOGLE_CLOUD_PROJECT || 'tccutfpets' }}"
          GOOGLE_APPLICATION_CREDENTIALS="/secrets/gcp-service-account.json"
          CLOUD_SQL_CONNECTION_NAME="${{ secrets.CLOUD_SQL_CONNECTION_NAME || 'tccutfpets:southamerica-east1:tcc' }}"

          # Database
          DB_CONNECTION="${{ secrets.DB_CONNECTION || 'pgsql' }}"
          DB_HOST="${{ secrets.DB_HOST || 'cloud-sql-proxy' }}"
          DB_PORT=${{ secrets.DB_PORT || 5432 }}
          DB_DATABASE=${{ secrets.DB_DATABASE }}
          DB_USERNAME=${{ secrets.DB_USERNAME }}
          DB_PASSWORD="${{ secrets.DB_PASSWORD }}"

          # Session
          SESSION_DRIVER="${{ secrets.SESSION_DRIVER || 'database' }}"
          SESSION_LIFETIME=${{ secrets.SESSION_LIFETIME || 120 }}
          SESSION_ENCRYPT="${{ secrets.SESSION_ENCRYPT || 'false' }}"
          SESSION_PATH="${{ secrets.SESSION_PATH || '/' }}"
          SESSION_DOMAIN="${{ secrets.SESSION_DOMAIN || '' }}"

          # Cache, Queue, Broadcasting
          BROADCAST_CONNECTION="${{ secrets.BROADCAST_CONNECTION || 'log' }}"
          FILESYSTEM_DISK="${{ secrets.FILESYSTEM_DISK || 'local' }}"
          QUEUE_CONNECTION="${{ secrets.QUEUE_CONNECTION || 'database' }}"
          QUEUE_MAX_TRIES=${{ secrets.QUEUE_MAX_TRIES || 5 }}
          CACHE_STORE="${{ secrets.CACHE_STORE || 'file' }}"
          CACHE_PREFIX="${{ secrets.CACHE_PREFIX || 'utfpets_cache' }}"

          # Redis
          REDIS_CLIENT="${{ secrets.REDIS_CLIENT || 'phpredis' }}"
          REDIS_HOST="${{ secrets.REDIS_HOST || '127.0.0.1' }}"
          REDIS_PASSWORD="${{ secrets.REDIS_PASSWORD || 'null' }}"
          REDIS_PORT=${{ secrets.REDIS_PORT || 6379 }}

          # Mail
          MAIL_MAILER="${{ secrets.MAIL_MAILER || 'log' }}"
          MAIL_HOST="${{ secrets.MAIL_HOST || 'localhost' }}"
          MAIL_PORT=${{ secrets.MAIL_PORT || 1025 }}
          MAIL_USERNAME="${{ secrets.MAIL_USERNAME || '' }}"
          MAIL_PASSWORD="${{ secrets.MAIL_PASSWORD || '' }}"
          MAIL_ENCRYPTION="${{ secrets.MAIL_ENCRYPTION || 'tls' }}"
          MAIL_FROM_ADDRESS="${{ secrets.MAIL_FROM_ADDRESS || 'noreply@utfpets.com' }}"
          MAIL_FROM_NAME="${{ secrets.MAIL_FROM_NAME || 'UTFPets' }}"

          # AWS
          AWS_ACCESS_KEY_ID="${{ secrets.AWS_ACCESS_KEY_ID || '' }}"
          AWS_SECRET_ACCESS_KEY="${{ secrets.AWS_SECRET_ACCESS_KEY || '' }}"
          AWS_DEFAULT_REGION="${{ secrets.AWS_DEFAULT_REGION || 'us-east-1' }}"
          AWS_BUCKET="${{ secrets.AWS_BUCKET || '' }}"
          AWS_USE_PATH_STYLE_ENDPOINT="${{ secrets.AWS_USE_PATH_STYLE_ENDPOINT || 'false' }}"

          # Cloudinary
          CLOUDINARY_URL="${{ secrets.CLOUDINARY_URL }}"
          CLOUDINARY_UPLOAD_PRESET="${{ secrets.CLOUDINARY_UPLOAD_PRESET }}"
          CLOUDINARY_CLOUD_NAME="${{ secrets.CLOUDINARY_CLOUD_NAME }}"
          CLOUDINARY_API_KEY="${{ secrets.CLOUDINARY_API_KEY }}"
          CLOUDINARY_API_SECRET="${{ secrets.CLOUDINARY_API_SECRET }}"

          # JWT
          JWT_SECRET="${{ secrets.JWT_SECRET }}"
          JWT_TTL=${{ secrets.JWT_TTL || 60 }}
          JWT_ALGO="${{ secrets.JWT_ALGO || 'HS256' }}"

          # CORS
          CORS_ALLOWED_ORIGINS="${{ secrets.CORS_ALLOWED_ORIGINS || 'https://utfpets.online,https://api.utfpets.online' }}"
          CORS_ALLOW_CREDENTIALS="${{ secrets.CORS_ALLOW_CREDENTIALS || 'true' }}"

          # Feature Flags
          FEATURE_PUSH_NOTIFICATIONS="${{ secrets.FEATURE_PUSH_NOTIFICATIONS || 'true' }}"
          FEATURE_WEIGHTS_TRACKING="${{ secrets.FEATURE_WEIGHTS_TRACKING || 'true' }}"
          FEATURE_CALENDAR_EXPORT="${{ secrets.FEATURE_CALENDAR_EXPORT || 'true' }}"

          # Weights Tracking
          WEIGHTS_MIN_VALUE="${{ secrets.WEIGHTS_MIN_VALUE || '0.1' }}"
          WEIGHTS_MAX_VALUE="${{ secrets.WEIGHTS_MAX_VALUE || '999.9' }}"

          # Calendar Export
          CALENDAR_DOMAIN="${{ secrets.CALENDAR_DOMAIN || 'utfpets.online' }}"

          # Push Notifications (FCM)
          FCM_KEY="${{ secrets.FCM_KEY || '' }}"
          FCM_PROJECT_ID="${{ secrets.FCM_PROJECT_ID || 'tccutfpets' }}"

          # PWA & Notifications
          VAPID_PUBLIC_KEY="${{ secrets.VAPID_PUBLIC_KEY }}"
          VAPID_PRIVATE_KEY="${{ secrets.VAPID_PRIVATE_KEY }}"
          VAPID_SUBJECT="${{ secrets.VAPID_SUBJECT || 'mailto:noreply@utfpets.com' }}"
          ENABLE_PWA="${{ secrets.ENABLE_PWA || 'true' }}"
          ENABLE_NOTIFICATIONS="${{ secrets.ENABLE_NOTIFICATIONS || 'true' }}"
          EOF

          gcloud compute scp /tmp/backend.env ${VM_NAME}:${APP_DIR}/backend/.env \
            --zone=${VM_ZONE} \
            --project=${PROJECT_ID}

          rm /tmp/backend.env
          echo "‚úÖ backend/.env file created on VM"

      - name: Create frontend .env file
        run: |
          echo "üìù Creating frontend/.env file from GitHub Secrets..."

          cat > /tmp/frontend.env <<'EOF'
          # UTFPets Frontend - Environment Variables (Production)

          # API Configuration
          VITE_API_URL="${{ secrets.VITE_API_URL || 'https://api.utfpets.online/api' }}"
          VITE_API_PUBLIC_URL="${{ secrets.VITE_API_PUBLIC_URL || 'https://api.utfpets.online' }}"

          # Application Info
          VITE_APP_NAME="${{ secrets.VITE_APP_NAME || 'UTFPets' }}"
          VITE_APP_VERSION="${{ secrets.VITE_APP_VERSION || '1.0.0' }}"

          # Environment
          NODE_ENV=production
          EOF

          gcloud compute scp /tmp/frontend.env ${VM_NAME}:${APP_DIR}/frontend/.env \
            --zone=${VM_ZONE} \
            --project=${PROJECT_ID}

          rm /tmp/frontend.env
          echo "‚úÖ frontend/.env file created on VM"

      - name: Create .env.production file
        run: |
          echo "üìù Creating .env.production file from GitHub Secrets..."

          cat > /tmp/production.env <<'EOF'
          # Docker Compose Environment Variables (Production)

          # Google Cloud SQL
          CLOUD_SQL_CONNECTION_NAME="${{ secrets.CLOUD_SQL_CONNECTION_NAME || 'tccutfpets:southamerica-east1:tcc' }}"

          # Database
          DB_CONNECTION="${{ secrets.DB_CONNECTION || 'pgsql' }}"
          DB_HOST="${{ secrets.DB_HOST || 'cloud-sql-proxy' }}"
          DB_DATABASE=${{ secrets.DB_DATABASE }}
          DB_USERNAME=${{ secrets.DB_USERNAME }}
          DB_PASSWORD="${{ secrets.DB_PASSWORD }}"
          DB_PORT=${{ secrets.DB_PORT || 5432 }}

          # Application
          APP_NAME="${{ secrets.APP_NAME || 'UTFPets API' }}"
          APP_ENV=production
          APP_KEY=${{ secrets.APP_KEY }}
          APP_DEBUG=false
          APP_URL=${{ secrets.APP_URL }}

          # JWT
          JWT_SECRET="${{ secrets.JWT_SECRET }}"
          JWT_TTL=${{ secrets.JWT_TTL || 60 }}

          # Cloudinary
          CLOUDINARY_URL="${{ secrets.CLOUDINARY_URL }}"
          CLOUDINARY_CLOUD_NAME="${{ secrets.CLOUDINARY_CLOUD_NAME }}"
          CLOUDINARY_UPLOAD_PRESET="${{ secrets.CLOUDINARY_UPLOAD_PRESET }}"

          # URLs
          API_PUBLIC_URL="${{ secrets.API_PUBLIC_URL || secrets.APP_URL }}"
          FRONTEND_URL="${{ secrets.FRONTEND_URL || 'https://utfpets.online' }}"

          # PWA & Notifications
          VAPID_PUBLIC_KEY="${{ secrets.VAPID_PUBLIC_KEY }}"
          ENABLE_PWA="${{ secrets.ENABLE_PWA || 'true' }}"
          ENABLE_NOTIFICATIONS="${{ secrets.ENABLE_NOTIFICATIONS || 'true' }}"
          EOF

          gcloud compute scp /tmp/production.env ${VM_NAME}:${APP_DIR}/.env.production \
            --zone=${VM_ZONE} \
            --project=${PROJECT_ID}

          rm /tmp/production.env
          echo "‚úÖ .env.production file created on VM"

      - name: Setup GCP service account
        run: |
          echo "üîê Setting up GCP service account credentials..."

          # Create temp file with service account JSON
          echo '${{ secrets.GCP_SA_KEY }}' > /tmp/gcp-sa-key.json

          # Create keys directory on VM with proper permissions and remove old file if exists
          gcloud compute ssh ${VM_NAME} \
            --zone=${VM_ZONE} \
            --project=${PROJECT_ID} \
            --command="
              sudo mkdir -p ${APP_DIR}/backend/storage/keys
              sudo rm -rf ${APP_DIR}/backend/storage/keys/gcp-service-account.json
              sudo chown \$USER:\$USER ${APP_DIR}/backend/storage/keys
              sudo chmod 755 ${APP_DIR}/backend/storage/keys
            "

          # Copy the service account key to VM (to home first, then move)
          gcloud compute scp /tmp/gcp-sa-key.json ${VM_NAME}:~/gcp-sa-key.json \
            --zone=${VM_ZONE} \
            --project=${PROJECT_ID}

          # Move to final location and set permissions
          gcloud compute ssh ${VM_NAME} \
            --zone=${VM_ZONE} \
            --project=${PROJECT_ID} \
            --command="
              mv ~/gcp-sa-key.json ${APP_DIR}/backend/storage/keys/gcp-service-account.json
              chmod 600 ${APP_DIR}/backend/storage/keys/gcp-service-account.json
              echo '‚úÖ Service account key configured'
            "

          # Cleanup local temp file
          rm /tmp/gcp-sa-key.json

      - name: Setup and start application
        run: |
          echo "‚öôÔ∏è  Setting up and starting application..."

          gcloud compute ssh ${VM_NAME} \
            --zone=${VM_ZONE} \
            --project=${PROJECT_ID} \
            --command="
              set -e
              cd ${APP_DIR}

              echo 'üîê Setting permissions...'
              chmod +x entrypoint.sh || true
              sudo chown -R 1000:1000 storage bootstrap/cache 2>/dev/null || true
              sudo chmod -R 775 storage bootstrap/cache 2>/dev/null || true

              echo 'üîê Fixing certbot permissions...'
              if [ -d certbot ]; then
                sudo chown -R rafaelsedor:rafaelsedor certbot/ 2>/dev/null || true
                sudo chmod -R 755 certbot/ 2>/dev/null || true
              fi

              echo 'üê≥ Building and starting containers...'
              docker compose up -d --build

              echo '‚è≥ Waiting for containers to be ready (may take several minutes for first build)...'
              timeout 300 bash -c 'until docker compose exec -T app php -r \"echo 1;\" 2>/dev/null; do echo \"Waiting for app...\"; sleep 5; done'

              echo 'üóÉÔ∏è  Running migrations...'
              docker compose exec -T app php artisan migrate --force || echo 'Warning: Migrations failed'

              echo '‚ö° Optimizing application...'
              docker compose exec -T app php artisan config:cache || true
              docker compose exec -T app php artisan route:cache || true
              docker compose exec -T app php artisan view:cache || true

              echo 'üìä Container status:'
              docker compose ps
            "

      - name: Health check
        run: |
          echo "üè• Performing health check..."

          MAX_ATTEMPTS=10
          ATTEMPT=0

          while [ $ATTEMPT -lt $MAX_ATTEMPTS ]; do
            ATTEMPT=$((ATTEMPT + 1))
            echo "Attempt $ATTEMPT/$MAX_ATTEMPTS..."

            if gcloud compute ssh ${VM_NAME} \
              --zone=${VM_ZONE} \
              --project=${PROJECT_ID} \
              --command="curl -f -s http://localhost/api/health" > /dev/null 2>&1; then
              echo "‚úÖ Health check passed!"
              exit 0
            fi

            if [ $ATTEMPT -lt $MAX_ATTEMPTS ]; then
              sleep 5
            fi
          done

          echo "‚ùå Health check failed after $MAX_ATTEMPTS attempts"
          exit 1

      - name: Cleanup old backups
        if: success()
        run: |
          echo "üßπ Cleaning up old backups..."

          gcloud compute ssh ${VM_NAME} \
            --zone=${VM_ZONE} \
            --project=${PROJECT_ID} \
            --command="
              sudo mkdir -p ${BACKUP_DIR}
              cd ${BACKUP_DIR}
              ls -dt utfpets_* 2>/dev/null | tail -n +6 | xargs sudo rm -rf || true
              echo \"Kept last 5 backups\"
            "

      - name: Deployment summary
        if: always()
        run: |
          echo "========================================="
          if [ "${{ job.status }}" == "success" ]; then
            echo "‚úÖ DEPLOYMENT SUCCESSFUL!"
            echo "========================================="
            echo "üåê API: http://34.39.150.157:8080"
            echo "üìö Swagger: http://34.39.150.157:8080/swagger"
            echo "üíö Health: http://34.39.150.157:8080/api/health"
            echo "========================================="
          else
            echo "‚ùå DEPLOYMENT FAILED!"
            echo "========================================="
            echo "Check logs above for details"
            echo "To rollback, connect to VM and restore backup"
            echo "========================================="
            exit 1
          fi
